# -*- coding: utf-8 -*-
"""Restaurant_tip.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hsDQfj4yv20mpOlsu4e_jqE027Jhx4YJ
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

try:
    df = pd.read_csv(r'/content/drive/MyDrive/Raw data/tip.csv')
    print("success")
except FileNotFoundError:
    print("failure")
    df = pd.DataFrame()

from google.colab import drive
drive.mount('/content/drive')

if not df.empty:
    print("/n---Total rows gotta be 244---")
    print(f"total rows: {len(df)}")
    print(f"total columns: {len(df.columns)}")
    print("/n---missing values and data types---")
    df.info()
else:
    print("go back to the file path")

print("/n--- feature engineering---")
 df['tip_percentage'] = np.where(df['total_bill']>0,
                            (df['tip']/df['total_bill']).round(4)*100,0)

print(df.info())

print(df[['tip','total_bill','tip_percentage']].describe().transpose())

print("\n--Outlier detection")
sns.set_style("whitegrid")
plt.figure(figsize=(8,6))
sns.boxplot(y= df["tip_percentage"])
plt.title("visualization 1")
plt.ylabel("tip_percentage")
plt.show()

print("\n--lets quantify outliers")
q1=df["tip_percentage"].quantile(0.25)
q3=df["tip_percentage"].quantile(0.75)
IQR = q3-q1
upper_bound=q3+1.5*IQR
outliers_count=df[df["tip_percentage"]>upper_bound].shape[0]
outlier_values=df[df['tip_percentage']>upper_bound]['tip_percentage'].tolist()
print(f"\n--q1: {q1:.2f}%")
print(f"\n--q3: {q3:.2f}%")
print(f"\n--IQR: {IQR:.2f}%")
print(f"\n--upper_bound: {upper_bound:.2f}%")
print(f"\n--outliers_count: {outliers_count}")
print(f"\n--oultiers: {outlier_values}")

print("\n--lets check the categorical values")
for col in ['sex','smoker','day','time']:
    print(f"{'col'}:{df[col].unique()}")

print(df.head())

print("\n--EDA")
sns.set_style("ticks")
plt.figure(figsize=(10,10))
sns.barplot(y=df["tip_percentage"],x=df["size"])
plt.title("EDA,tip_percentage Vs size")
plt.ylabel("tip_percentage")
plt.xlabel("size")
plt.show

df_cleaned=df[~(df["tip_percentage"]>upper_bound)].copy()
rows_removed = len(df) - len(df_cleaned)
print(f"\n--length of original df:{len(df)}")
print(f"\n--removed rows:{(rows_removed)}")
print(f"\n--length of clean data set:{len(df_cleaned)}")

print("EDA:tip_percentage Vs sex")
sns.set_style("dark")
plt.figure(figsize=(8,6))
plt.title("EDA:tip_percentage Vs sex")
sns.barplot(y=df_cleaned["tip_percentage"],x=df_cleaned["sex"])
plt.ylabel("tip_percentage")
plt.xlabel("sex")
plt.show

print("EDA:tip_percentage Vs sex Vs smoker")
sns.set_style("dark")
plt.figure(figsize=(10,8))
plt.title("EDA:tip_percentage Vs sex Vs smoking")
sns.barplot(y=df_cleaned["tip_percentage"],x=df_cleaned["smoker"],hue=df_cleaned["sex"],palette="viridis",dodge=True)
plt.ylabel("tip_percentage")
plt.xlabel("sex")
plt.show

print("EDA:tip_percentage  Vs time")
sns.set_style("dark")
plt.figure(figsize=(10,8))
plt.title("EDA:tip_percentage Vs time")
sns.barplot(y=df_cleaned["tip_percentage"],x=df_cleaned["time"])
plt.ylabel("tip_percentage")
plt.xlabel("time")
plt.show

print("EDA:tip_percentage  Vs time Vs sex")
sns.set_style("dark")
plt.figure(figsize=(10,8))
plt.title("EDA:tip_percentage Vs sex Vs time")
sns.barplot(y=df_cleaned["tip_percentage"],x=df_cleaned["time"],hue=df_cleaned["sex"],palette="viridis",dodge=True)
plt.ylabel("tip_percentage")
plt.xlabel("time")
plt.show

print("one hot-encoding to get redy for correlation heatmap")
categorical_cols=['smoker','time','sex','day']
df_encoded= pd.get_dummies(df_cleaned,columns=categorical_cols,drop_first=True,dtype=int)
print(f"old columns : {df_cleaned.shape[1]}")
print(f"encoded: {df_encoded.shape[1]}")

print("lets get ready for the heatmap")
target_col='tip_percentage'
independent_cols= [col for col in df_encoded.columns if col not in['tip',target_col]]
corr_matrix=df_encoded[[target_col]+independent_cols].corr().loc[[target_col],independent_cols].T
corr_matrix.columns=['R of target_col']
corr_matrix = corr_matrix.sort_values(by='R of target_col', ascending=False)
plt.figure(figsize=(6, 8))
sns.heatmap(
        corr_matrix,
        annot=True,
        cmap='coolwarm',
        fmt=".2f",
        linewidths=.5,
        cbar=False,
    )
plt.title('Correlation of Tip Percentage with ALL Independent Variables')
plt.yticks(rotation=0)
plt.show()

from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
X = df_encoded[independent_cols]
y = df_encoded[target_col]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
rf_regressor = RandomForestRegressor(random_state=42)
rf_regressor.fit(X_train, y_train)
print("Random forest  Regressor trained successfully.")

    # 4. Extract Feature Importance
feature_importances = pd.Series(rf_regressor.feature_importances_, index=X.columns)

    # 5. Visualize Importance
plt.figure(figsize=(8, 6))
    # Sort the features for clear visualization
feature_importances.sort_values(ascending=False).plot(kind='barh', color='skyblue')

plt.title('Decision Tree Feature Importance for Tip Percentage')
plt.xlabel('Importance Score (Gini/Variance Reduction)')
plt.ylabel('Feature')
plt.gca().invert_yaxis() # Put the most important feature at the top
plt.show()

print(df.groupby('smoker')['tip_percentage'].mean())

y_pred = rf_regressor.predict(X_test)

from sklearn.metrics import mean_squared_error, r2_score
r2 = r2_score(y_test, y_pred)

rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f"R-squared (R²): {r2:.4f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")

print("\nEvaluation complete. R² indicates the percentage of variance explained.")